---
layout: doc
title: Local Kubernetes Cluster Setup With minikube
description: Provision minikube for local development and testing of FusionAuth kubernetes deployments
keywords: docker kubernetes k8s container aws
---
:page-liquid:

== Overview

Having the capability to deploy applications in a local Kubernetes environment allows engineers to quickly develop, test, and demo without the operational overhead of a full-blown cluster. This is precisely what https://minikube.sigs.k8s.io/docs[minikube] is designed for by creating a single-node cluster within a virtual machine.

This guide will show you how to install and configure minikube and then install FusionAuth, including the required PostgreSQL database and Elasticsearch, on your minikube cluster.

**Figure 1** shows an example of the minikube configuration that you will create. The cluster will consist of three https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/[Replica Sets], one for each deployment of Elasticsearch, Postgresql, and FusionAuth. Each will have one https://kubernetes.io/docs/concepts/workloads/pods/[Pod], with exception of Elasticsearch which will have three. You could scale it down to one pod, but for simplicity, you will use the default settings for the Elasticsearch chart.
Each deployment exposes a https://kubernetes.io/docs/concepts/services-networking/service/[Service] which exposes each application as a network service.
Finally, you will use an https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/[Ingress Controller] of type https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/[Load Balancer] that allows external traffic, or in this case, traffic from `localhost` to the cluster.

image::installation-guides/kubernetes/fa-minikube.png[title=Example Kubernetes configuration in minikube,FusionAuth Minikube Architecture,width=1200,role=shadowed]
:figure-caption!:

== Requirements

Before you begin, you will need to have the following installed.

* https://docs.docker.com/get-docker/[Docker Desktop] - The virtual machine environment you will use to run minikube.
* `helm` - Package manager used for installing and managing Kubernetes applications. In this guide, you will be using a Helm chart to install FusionAuth, a Postgresql database, and Elasticsearch cluster. For more information, see https://helm.sh/docs/intro/install/[Installing Helm].
* `kubectl` - Command line tool that interacts with the Kubernetes API server and is useful for managing Kubernetes clusters. Before proceeding, follow the installation documentation that corresponds to your platform found https://kubernetes.io/docs/tasks/tools/[here].

== Install minikube

Navigate to https://minikube.sigs.k8s.io/docs/start/[minikube start] and complete step one by selecting the options that apply to your local machine.

For example, if you are running on `macOS` with `x86-64` architecture, Homebrew is a popular [field]#installer type#:

[source,shell,title=Install minikube]
----
$ brew install minikube
----

=== Start minikube

Since you will be deploying multiple applications, you will want to start minikube using some additional resource considerations.

[WARNING.warning]
====
Before proceeding, make sure Docker Desktop has sufficient resources allocated. These settings can be found in Docker Desktop by navigating to *Preferences* and then clicking on *Resources* in the side menu bar.
====

Start minikube by additionally specifying [field]#cpus# and [field]#memory#.

[source,shell,title=Start minikube]
----
$ minikube start --cpus 4 --memory 5g
----

[NOTE.note]
====
This minikube setting is a general recommendation that has been tested for this guide based on resource requirements of FusionAuth, Postgresql, and Elasticsearch.
====

When the command finishes, it will configure `kubectl` to point to the minikube cluster. You can confirm this by checking the status:

[source,shell,title=Get minikube status]
----
$ minikube status

minikube
type: Control Plane
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
----

Or by running the `kubectl` command to view pods running on the cluster. Use the `-A` or `--all-namespaces` to list all pods deployed to the cluster.
Since you have not deployed anything yet, only pods in the `kube-system` namespace will be returned:

[source,shell,title=Get all pods deployed on the cluster]
----
$ kubectl get pods -A

NAMESPACE     NAME                               READY   STATUS    RESTARTS       AGE
kube-system   coredns-78fcd69978-tr4jt           1/1     Running   0              9m38s
kube-system   etcd-minikube                      1/1     Running   0              9m53s
kube-system   kube-apiserver-minikube            1/1     Running   0              9m51s
kube-system   kube-controller-manager-minikube   1/1     Running   0              9m54s
kube-system   kube-proxy-2h8b2                   1/1     Running   0              9m38s
kube-system   kube-scheduler-minikube            1/1     Running   0              9m51s
kube-system   storage-provisioner                1/1     Running   1 (9m8s ago)   9m50s
----

== Deploy Postgresql

Start by adding the bitnami helm repository that contains the Postgresql chart:

[source,shell,title=Add PostgreSQL chart repository]
----
$ helm repo add bitnami https://charts.bitnami.com/bitnami
----

To list all of the Helm repositories that you have added, execute this command:

[source,shell,title=List chart repositories]
----
$ helm repo list
----

The resulting output will display the chart you just added and any other helm charts that you may have added previously.

[source,shell,title=Output]
----
NAME      	URL
bitnami   	https://charts.bitnami.com/bitnami
----

Install the chart using the `helm` command. Set the [field]#postgresqlPassword# value using the `set` flag for the `postgres` user. In this example, the [field]#release# field is set to `pg-minikube`:

[source,shell,title=Install the postgresql chart]
----
$ helm install pg-minikube bitnami/postgresql \
  --set postgresqlPassword=<your-postgresql-password>
----

When completed successfully, the output will contain some useful information about your deployment:

[source,helmtext,title=Output]
----
** Please be patient while the chart is being deployed **

PostgreSQL can be accessed via port 5432 on the following DNS names from within your cluster:

    pg-minikube-postgresql.default.svc.cluster.local - Read/Write connection

To get the password for "postgres" run:

    export POSTGRES_PASSWORD=$(kubectl get secret --namespace default pg-minikube-postgresql -o jsonpath="{.data.postgresql-password}" | base64 --decode)

To connect to your database run the following command:

    kubectl run pg-minikube-postgresql-client --rm --tty -i --restart='Never' --namespace default --image docker.io/bitnami/postgresql:11.13.0-debian-10-r40 --env="PGPASSWORD=$POSTGRES_PASSWORD" --command -- psql --host pg-minikube-postgresql -U postgres -d postgres -p 5432

To connect to your database from outside the cluster execute the following commands:

    kubectl port-forward --namespace default svc/pg-minikube-postgresql 5432:5432 &
    PGPASSWORD="$POSTGRES_PASSWORD" psql --host 127.0.0.1 -U postgres -d postgres -p 5432
----

When you deploy FusionAuth, you will need to use the DNS name `pg-minikube-postgresql.default.svc.cluster.local` as seen above and the password that you set in the install command.

You can test your deployment by attempting to connect to the database following the instructions in the output. You can also verify the `pg-minikube-postgresql` pod by again retrieving pods with `kubectl`. The following command requests pods in the `default` namespace with output (`-o`) containing additional information such as [field]#IP Address#:

[source,shell,title=Get pods in the default namespace]
----
$ kubectl get pods -n default -o wide
----

The resulting output will show `1/1` pg-minikube-postgresql pod in a `READY` state:

[source,shell,title=Output]
----
NAME                       READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
pg-minikube-postgresql-0   1/1     Running   0          8m33s   172.17.0.3   minikube   <none>           <none>
----

include::/docs/v1/tech/installation-guide/kubernetes/_pod-ready.adoc[]

You can also retrieve active services on the cluster. A Kubernetes https://kubernetes.io/docs/concepts/services-networking/service/[Service] exposes applications running on a pod as a network service. The following command will display the new service exposing the Postgresql application with an IP address running on port `5432`:

[source,shell,title=Get services]
----
$ kubectl get services -n default

NAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
kubernetes                        ClusterIP   10.96.0.1        <none>        443/TCP    82m
pg-minikube-postgresql            ClusterIP   10.108.174.128   <none>        5432/TCP   27m
pg-minikube-postgresql-headless   ClusterIP   None             <none>        5432/TCP   27m
----

In addition to the `pg-minikube-postgresql` service, you will see another service with the name `kubernetes`. This service is responsible for directing traffic to the Kubernetes API server.

[NOTE.note]
====
You also might have noticed the additional postgresql service `pg-minikube-postgresql-headless`. This is what is known in Kubernetes as a https://kubernetes.io/docs/concepts/services-networking/service/#headless-services[Headless Service]. To read more about these types of services, see the official Kubernetes documentation https://kubernetes.io/docs/concepts/services-networking/service/#headless-services[here].
====

== Deploy Elasticsearch

Start by adding the https://artifacthub.io/packages/helm/elastic/elasticsearch[Elasticsearch Helm Chart] repository by running this command:

[source,shell,title=Add Elasticsearch chart repository]
----
$ helm repo add elastic https://helm.elastic.co
----

You will now have the two charts that you have added in this guide in addition to any other charts you have added if you have used Helm prior to this guide.

[source,shell,title=List chart repositories]
----
$ helm repo list

NAME      	URL
bitnami   	https://charts.bitnami.com/bitnami
elastic   	https://helm.elastic.co
----

Before installing, you will need to download a copy of a recommended configuration for minikube virtual machines:

[source,shell,title=Download example minikube configuration]
----
$ curl -O https://raw.githubusercontent.com/elastic/Helm-charts/master/elasticsearch/examples/minikube/values.yaml
----

The contents of this configuration uses a smaller JVM heap, smaller memory per pods requests, and smaller persistent volumes.
The `values.yaml` file you downloaded should look like this:

[source,helmyaml,title=Configuration details]
----
# Permit co-located instances for solitary minikube virtual machines.
antiAffinity: "soft"

# Shrink default JVM heap.
esJavaOpts: "-Xmx128m -Xms128m"

# Allocate smaller chunks of memory per pod.
resources:
  requests:
    cpu: "100m"
    memory: "512M"
  limits:
    cpu: "1000m"
    memory: "512M"

# Request smaller persistent volumes.
volumeClaimTemplate:
  accessModes: [ "ReadWriteOnce" ]
  storageClassName: "standard"
  resources:
    requests:
      storage: 100M
----

Now install the Elasticsearch chart using this `values.yaml` configuration by including the `-f` flag:

[source,shell,title=Install elasticsearch chart]
----
$ helm install es-minikube elastic/elasticsearch -f values.yaml
----

Be aware, it may take a minute or two for the pods to reach a `READY` state.

Confirm your deployment by retrieving active pods in the cluster.

[source,shell,title=Get pods]
----
$ kubectl get pods -n default -o wide
----

The resulting output will show three pods for each elasticsearch node:

[source,shell,title=Output]
----
NAME                         READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
elasticsearch-master-0       1/1     Running   0          7m17s   172.17.0.5   minikube   <none>           <none>
elasticsearch-master-1       1/1     Running   0          7m17s   172.17.0.4   minikube   <none>           <none>
elasticsearch-master-2       1/1     Running   0          7m17s   172.17.0.6   minikube   <none>           <none>
pg-minikube-postgresql-0     1/1     Running   0          39m     172.17.0.3   minikube   <none>           <none>
----

Running the `kubectl` command to get service information again will show that the installed Elasticsearch chart exposes the `elasticsearch-master` https://kubernetes.io/docs/concepts/services-networking/service/[Service] running at a dedicated IP address on port `9200`:

[source,shell,title=Get services]
----
$ kubectl get services -n default

NAME                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
elasticsearch-master              ClusterIP   10.107.78.6      <none>        9200/TCP,9300/TCP   3m38s
elasticsearch-master-headless     ClusterIP   None             <none>        9200/TCP,9300/TCP   3m38s
kubernetes                        ClusterIP   10.96.0.1        <none>        443/TCP             98m
pg-minikube-postgresql            ClusterIP   10.100.117.198   <none>        5432/TCP            92m
pg-minikube-postgresql-headless   ClusterIP   None             <none>        5432/TCP            92m
----

=== Kubernetes DNS

The default installation of minikube enables https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns[kube-dns], a https://kubernetes.io/docs/concepts/services-networking/service/[Service] that automatically assigns dns names to other services in the cluster.

When you installed <<Deploy Postgresql, Postgresql>> and <<Deploy Elasticsearch, Elasticsearch>>, each service that was created was assigned the following dns names respectively by **kube-dns**:

* `pg-minikube-postgresql.default.svc.cluster.local`
* `elasticsearch-master.default.svc.cluster.local`

You will use these values when deploying FusionAuth in the next section.

For more information on DNS see Kubernetes documentation for https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/[DNS for Services and Pods].

=== Deploy FusionAuth

Now that you have a Kubernetes cluster actively running a database and Elasticsearch, you can go ahead and configure FusionAuth and deploy it to the cluster.

To get started, the first thing to do is add the FusionAuth Helm Chart repository. This can be done with the following command:

[source,shell,title=Add a chart repository]
----
$ helm repo add fusionauth https://fusionauth.github.io/charts
----

Next, download the example `values.yaml` for this guide:

[source,shell,title=Download example FusionAuth configuration]
----
$ curl -O https://raw.githubusercontent.com/FusionAuth/charts/master/chart/examples/minikube/values.yaml
----

Deploy FusionAuth by using the FusionAuth chart using the [field]#set# flag to apply override values. You will also use the `-f` option providing the path to your minikube `values.yaml`:

[NOTE.note]
====
include::/docs/v1/tech/installation-guide/kubernetes/_set-flag.adoc[]
====

[source,shell,title=Install FusionAuth chart]
----
$ helm install fa-minikube fusionauth/fusionauth -f ./values.yaml \
  --set database.host=pg-minikube-postgresql.default.svc.cluster.local \
  --set database.root.password=<your-postgresql-password> \
  --set search.host=elasticsearch-master.default.svc.cluster.local
----

The last thing you need to do is to configure the cluster to be able to receive external requests. To direct external traffic to your cluster, you will use an https://kubernetes.io/docs/concepts/services-networking/ingress/[Ingress], a component that defines how external traffic should be handled, and an https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/[Ingress Controller] that implements those rules.

The FusionAuth chart already installed an https://kubernetes.io/docs/concepts/services-networking/ingress/[Ingress] resource on the cluster as configured in the `values.yaml` that you downloaded. For reference, this is what the definition looks like:

[source,helmyaml,title=FusionAuth Ingress]
----
# Source: fusionauth/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: fa-minikube-fusionauth
  labels:
    app.kubernetes.io/name: fusionauth
    helm.sh/chart: fusionauth-0.10.5
    app.kubernetes.io/instance: fa-minikube
    app.kubernetes.io/managed-by: Helm
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  rules:
    - host: "localhost"
      http:
        paths:
          - path: "/"
            pathType: "Prefix"
            backend:
              service:
                name: fa-minikube-fusionauth
                port:
                  name: https
----

The rules for this Ingress resource indicate that requests from `localhost` root path context, or `/`, should be directed to the `fa-minikube-fusionauth` service.

The last thing you need is an https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/[Ingress Controller]. You will use the NGINX Ingress controller for this.

To install the the Ingress controller, add the repo and install the chart by running the following commands:

[source,shell,title=Add ingress-nginx chart repository]
----
$ helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
----

[source,shell,title=Install ingress-nginx chart]
----
$ helm install fa-loadbalancer ingress-nginx/ingress-nginx
----

When completed, you will see a new service of type `LoadBalancer` and external IP value of `<pending>`. Once you allow external traffic to reach minikube, the external IP address will be set to `127.0.0.1`, or `localhost`, as defined in your FusionAuth ingress definition.

Use minikube tunnel to direct external network traffic to the cluster:

[source,shell,title=minikube tunnel]
----
$ minikube tunnel
❗  The service/ingress fa-loadbalancer-ingress-nginx-controller requires privileged ports to be exposed: [80 443]
🔑  sudo permission will be asked for it.
🏃  Starting tunnel for service fa-loadbalancer-ingress-nginx-controller.
❗  The service/ingress fa-minikube-fusionauth requires privileged ports to be exposed: [80 443]
🔑  sudo permission will be asked for it.
Password:🏃
Starting tunnel for service fa-minikube-fusionauth.
----

Navigating to `localhost` in the browser will now direct us to FusionAuth running on the cluster.

image::installation-guides/kubernetes/fa-initial-config.png[FusionAuth Setup Wizard,,width=1200,role=shadowed]

At this point, you should have a total of 6 `READY` pods including FusionAuth!

[source,shell,title=Get pods]
----
$ kubectl get pods -n default -o wide
NAME                                                            READY   STATUS    RESTARTS   AGE     IP            NODE       NOMINATED NODE   READINESS GATES
curl                                                            1/1     Running   0          7h39m   172.17.0.10   minikube   <none>           <none>
elasticsearch-master-0                                          1/1     Running   0          23h     172.17.0.5    minikube   <none>           <none>
elasticsearch-master-1                                          1/1     Running   0          23h     172.17.0.4    minikube   <none>           <none>
elasticsearch-master-2                                          1/1     Running   0          23h     172.17.0.6    minikube   <none>           <none>
fa-minikube-fusionauth-864b9f95f9-clsfd                         1/1     Running   0          7m31s   172.17.0.7    minikube   <none>           <none>
fusionauth-minikube-ingress-nginx-controller-5899f64867-g4nk5   1/1     Running   0          129m    172.17.0.8    minikube   <none>           <none>
pg-minikube-postgresql-0                                        1/1     Running   0          24h     172.17.0.3    minikube   <none>           <none>
----

Congratulations! You are now running FusionAuth locally on a Minikube Kubernetes cluster.








